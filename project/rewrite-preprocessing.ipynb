{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a52bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.spatial.distance import euclidean\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import hyperparameters as hp\n",
    "import random\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "path = hp.FLOWDATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5152daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_long_nan_sections(df, max_gap):\n",
    "    # create a mask for all of the rows with missing values\n",
    "    missing_vals = df.isna()\n",
    "    \n",
    "    prev_row_missing_vals = missing_vals.shift()\n",
    "\n",
    "    # find the rows where the value of a sensor changes from nan > value, or value > nan\n",
    "    transition_rows = missing_vals != prev_row_missing_vals\n",
    "\n",
    "    # assign an id number to each block of vals\n",
    "    block_ids = transition_rows.cumsum()\n",
    "\n",
    "    # find the length of each gap\n",
    "    gap_lengths = missing_vals.groupby(block_ids).transform('sum')\n",
    "\n",
    "    # identify all gaps which are longer than 4 hours\n",
    "    long_gaps = missing_vals & (gap_lengths > max_gap)\n",
    "\n",
    "    return long_gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c250c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the flow data file\n",
    "flowdata_df = pd.read_csv(path, index_col=0)\n",
    "flowdata_df.index = pd.to_datetime(flowdata_df.index, format='%d/%m/%Y %H:%M')\n",
    "\n",
    "# Removing a sensor with a large number of missing values\n",
    "flowdata_df = flowdata_df.drop('1615', axis=1)\n",
    "\n",
    "flowdata_df = flowdata_df.rename(columns=hp.SENSOR_DMA_TO_ID)\n",
    "flowdata_df = flowdata_df.sort_index(axis=1)\n",
    "\n",
    "# Removing rows which have outliers or are part of long sections of missing values\n",
    "rows_to_remove = pd.Series(False, index=flowdata_df.index) \n",
    "for col in flowdata_df.columns:\n",
    "    rows_to_remove |= find_long_nan_sections(flowdata_df[col], hp.MAX_GAP)\n",
    "    #rows_to_remove |= find_outlier_values(flowdata_df[col])\n",
    "flowdata_df = flowdata_df[rows_to_remove == False]\n",
    "\n",
    "# Imputing short ranges of missing values\n",
    "flowdata_df = flowdata_df.interpolate(method='spline', order = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f47f4ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows per month: year_month\n",
      "2020-01    2976\n",
      "2020-02    2699\n",
      "2020-03    2976\n",
      "2020-04    2756\n",
      "2020-05    1581\n",
      "2020-06    2067\n",
      "2020-07    2147\n",
      "2020-08    2098\n",
      "2020-09    1522\n",
      "2020-10     200\n",
      "2020-11     985\n",
      "2020-12    1157\n",
      "2021-01    2361\n",
      "2021-02    2688\n",
      "2021-03    2976\n",
      "2021-04    2880\n",
      "2021-05     457\n",
      "2022-02     584\n",
      "2022-03    2029\n",
      "2023-05    2195\n",
      "2023-06    2817\n",
      "2023-07    2221\n",
      "2023-08    2884\n",
      "2023-09    2796\n",
      "2023-10    2757\n",
      "2023-11    2354\n",
      "2023-12    2549\n",
      "2024-01    1969\n",
      "2024-02    2519\n",
      "2024-03    2698\n",
      "2024-04    1885\n",
      "2024-05    2804\n",
      "2024-06    2317\n",
      "2024-07    2495\n",
      "2024-08    1220\n",
      "2024-09     459\n",
      "Freq: M, Name: count, dtype: int64\n",
      "Rows in train set: 52666\n",
      "Rows in val set: 8875\n",
      "Rows in test set: 14537\n"
     ]
    }
   ],
   "source": [
    "def month_based_train_val_test_split(flowdata_df, train_val_test_ratios):\n",
    "    # get all the months\n",
    "    df_month_strata = pd.DataFrame(index=flowdata_df.index)\n",
    "    # Use the index instead of a 'timestamp' column\n",
    "    df_month_strata['year_month'] = flowdata_df.index.to_period('M')\n",
    "    print(f\"Rows per month: {df_month_strata['year_month'].value_counts().sort_index()}\")\n",
    "\n",
    "    months = df_month_strata['year_month'].unique()\n",
    "    random.shuffle(months)\n",
    "\n",
    "    # assign each month to a set\n",
    "    num_months = df_month_strata['year_month'].nunique()\n",
    "    train_ratio, val_ratio, test_ratio = train_val_test_ratios\n",
    "\n",
    "    num_months_train = int(num_months * train_ratio)\n",
    "    num_months_val = int(num_months * val_ratio)\n",
    "    num_months_test = num_months - num_months_train - num_months_val\n",
    "\n",
    "    train_months = months[:num_months_train]\n",
    "    val_months = months[num_months_train:num_months_train + num_months_val]\n",
    "    test_months = months[num_months_train + num_months_val:]\n",
    "\n",
    "    # split the data into the sets\n",
    "    train_df = flowdata_df[df_month_strata['year_month'].isin(train_months)]\n",
    "    val_df = flowdata_df[df_month_strata['year_month'].isin(val_months)]\n",
    "    test_df = flowdata_df[df_month_strata['year_month'].isin(test_months)]\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "train_df, val_df, test_df = month_based_train_val_test_split(flowdata_df, hp.TRAIN_VAL_TEST_SPLIT)\n",
    "\n",
    "for name, df in zip([\"train\", \"val\", \"test\"], [train_df, val_df, test_df]):\n",
    "     print(f'Rows in {name} set:', len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9652cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_strata(df):\n",
    "    \"\"\"\n",
    "    Takes a timeseries dataframe, and creates a corresponding series specificying each row's strata.\n",
    "    \"\"\"\n",
    "\n",
    "    strata_dict = {\n",
    "        'time_of_day': {\n",
    "            'feature_origin': df.index.hour,\n",
    "            'bins': [0, 6, 12, 14, 18, 22, 24],  \n",
    "            'labels': ['night', 'morning', 'midday', 'afternoon', 'evening', 'night']\n",
    "        },\n",
    "        'part_of_week': {\n",
    "            'feature_origin': df.index.dayofweek,\n",
    "            'bins': [0, 5, 7], \n",
    "            'labels': ['weekday', 'weekend']\n",
    "        },\n",
    "        'season': {\n",
    "            'feature_origin': df.index.month,\n",
    "            'bins': [0, 3, 6, 9, 12, 13], \n",
    "            'labels': ['winter', 'spring', 'summer', 'autumn', 'winter']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    strata_df = pd.DataFrame(index=df.index)\n",
    "\n",
    "    for strata_name, strata_info in strata_dict.items():\n",
    "        strata_df[strata_name] = pd.cut(\n",
    "            strata_info['feature_origin'],\n",
    "            bins=strata_info['bins'],\n",
    "            labels=strata_info['labels'],\n",
    "            right=False,  \n",
    "            include_lowest=True,\n",
    "            ordered=False\n",
    "        )\n",
    "\n",
    "    strata_df['strata'] = strata_df['part_of_week'].astype(str) + '_' + strata_df['season'].astype(str)\n",
    "\n",
    "    return strata_df\n",
    "\n",
    "dfs = [train_df, val_df, test_df]\n",
    "overlap = [True, True, False]\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    # Actual code\n",
    "    strata_df = assign_strata(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05398d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows per month: year_month\n",
      "2020-01    2976\n",
      "2020-02    2699\n",
      "2020-03    2976\n",
      "2020-04    2756\n",
      "2020-05    1581\n",
      "2020-06    2067\n",
      "2020-07    2147\n",
      "2020-08    2098\n",
      "2020-09    1522\n",
      "2020-10     200\n",
      "2020-11     985\n",
      "2020-12    1157\n",
      "2021-01    2361\n",
      "2021-02    2688\n",
      "2021-03    2976\n",
      "2021-04    2880\n",
      "2021-05     457\n",
      "2022-02     584\n",
      "2022-03    2029\n",
      "2023-05    2195\n",
      "2023-06    2817\n",
      "2023-07    2221\n",
      "2023-08    2884\n",
      "2023-09    2796\n",
      "2023-10    2757\n",
      "2023-11    2354\n",
      "2023-12    2549\n",
      "2024-01    1969\n",
      "2024-02    2519\n",
      "2024-03    2698\n",
      "2024-04    1885\n",
      "2024-05    2804\n",
      "2024-06    2317\n",
      "2024-07    2495\n",
      "2024-08    1220\n",
      "2024-09     459\n",
      "Freq: M, Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows per month: year_month\n",
      "2020-01    2976\n",
      "2020-02    2699\n",
      "2020-03    2976\n",
      "2020-04    2756\n",
      "2020-05    1581\n",
      "2020-06    2067\n",
      "2020-07    2147\n",
      "2020-08    2098\n",
      "2020-09    1522\n",
      "2020-10     200\n",
      "2020-11     985\n",
      "2020-12    1157\n",
      "2021-01    2361\n",
      "2021-02    2688\n",
      "2021-03    2976\n",
      "2021-04    2880\n",
      "2021-05     457\n",
      "2022-02     584\n",
      "2022-03    2029\n",
      "2023-05    2195\n",
      "2023-06    2817\n",
      "2023-07    2221\n",
      "2023-08    2884\n",
      "2023-09    2796\n",
      "2023-10    2757\n",
      "2023-11    2354\n",
      "2023-12    2549\n",
      "2024-01    1969\n",
      "2024-02    2519\n",
      "2024-03    2698\n",
      "2024-04    1885\n",
      "2024-05    2804\n",
      "2024-06    2317\n",
      "2024-07    2495\n",
      "2024-08    1220\n",
      "2024-09     459\n",
      "Freq: M, Name: count, dtype: int64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'segment_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     67\u001b[39m set_name = set_names[i]\n\u001b[32m     68\u001b[39m strata_df = assign_strata(df)\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m samples_df, samples_strata_df = \u001b[43mcreate_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrata_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlap\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverlap\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mSamples created from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m set:\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(samples_df))\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(samples_df) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mcreate_samples\u001b[39m\u001b[34m(df, df_strata, sample_length, set_name, overlap)\u001b[39m\n\u001b[32m     18\u001b[39m segments_df = df.copy()\n\u001b[32m     19\u001b[39m segments_df[\u001b[33m'\u001b[39m\u001b[33msegment_id\u001b[39m\u001b[33m'\u001b[39m] = gap_mask.cumsum()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m segments_df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msegment_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mSegments in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(segments_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m overlap:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ameli\\Documents\\Uni\\year-3-notes\\diss\\Code\\test\\test-venv\\Lib\\site-packages\\pandas\\core\\frame.py:9210\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9208\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9213\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9216\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9220\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ameli\\Documents\\Uni\\year-3-notes\\diss\\Code\\test\\test-venv\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1331\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1328\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1330\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1331\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1342\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ameli\\Documents\\Uni\\year-3-notes\\diss\\Code\\test\\test-venv\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'segment_id'"
     ]
    }
   ],
   "source": [
    "def create_samples(df, df_strata, sample_length, set_name, overlap):\n",
    "    \"\"\"\n",
    "    Creates samples of the data with a given length and overlap.\n",
    "\n",
    "    Note: \n",
    "    - Currently all samples will start at the same time of day, as each one is 5 days long\n",
    "    - This would make the model struggle with differently timed inputs\n",
    "    - I will need to eventually add random starting points for the samples, but for now I will just create the samples with a fixed starting point to test the model\n",
    "    \"\"\"\n",
    "\n",
    "    samples_df = pd.DataFrame(columns=hp.SENSOR_COLS)\n",
    "    samples_strata_df = pd.Series(dtype=str, index=samples_df.index)\n",
    "\n",
    "    # Find all the gaps in the data (where there are missing time steps / it is not continuous)\n",
    "    gap_mask = df.index.to_series().diff() > pd.Timedelta(minutes=15)\n",
    "\n",
    "    time_diffs = df.index.to_series().diff()\n",
    "\n",
    "    # Identify actual gaps (where diff > 15 minutes)\n",
    "    gap_durations = time_diffs[time_diffs > pd.Timedelta(minutes=15)]\n",
    "    print(f'\\nGap summary for {set_name} set:')\n",
    "    for idx, gap in gap_durations.items():\n",
    "        prev_time = df.index[df.index.get_loc(idx) - 1]\n",
    "        print(f\"Gap before {idx}: {gap} (from {prev_time} to {idx})\")\n",
    "\n",
    "    # Split the data into all of the continous segments\n",
    "    df = df.copy()\n",
    "    df['segment_id'] = gap_mask.cumsum()\n",
    "    segments_df = df.groupby('segment_id')\n",
    "\n",
    "    print(f'Segments in {set_name} set: {len(segments_df)}')\n",
    "\n",
    "    if overlap:\n",
    "            step = sample_length // 2\n",
    "    else:\n",
    "        step = sample_length\n",
    "\n",
    "    # Split the data into all of the continuous segments and iterate through each segment\n",
    "    for _, segment in segments_df:\n",
    "\n",
    "        print(f'Processing segment {segment[\"segment_id\"].iloc[0]} in {set_name} set, length: {len(segment)}, from {segment.index[0]} to {segment.index[-1]}')\n",
    "\n",
    "        # Get rid of the segment_id column\n",
    "        segment = segment.drop(columns='segment_id')\n",
    "\n",
    "        strata_segment = df_strata.loc[segment.index]\n",
    "\n",
    "        num_samples = 0\n",
    "        i = 0\n",
    "        while i + sample_length <= len(segment):\n",
    "            index = len(samples_df)\n",
    "\n",
    "            sample_row = {}\n",
    "            strata_row = {}\n",
    "            sample = segment[i:i + sample_length]\n",
    "            strata_sample = strata_segment[i:i + sample_length]\n",
    "\n",
    "            for col in hp.SENSOR_COLS:\n",
    "                sample_row[col] = sample[col].values\n",
    "            strata_row = strata_sample.values\n",
    "\n",
    "            samples_df.loc[index] = sample_row\n",
    "            samples_strata_df.loc[index] = strata_row\n",
    "\n",
    "            i += step\n",
    "            num_samples += 1\n",
    "        \n",
    "        print(f'Created {num_samples}')\n",
    "        \n",
    "\n",
    "    \n",
    "    return samples_df, samples_strata_df\n",
    "\n",
    "window_size = hp.TOTAL_WINDOW\n",
    "train_df, val_df, test_df = month_based_train_val_test_split(flowdata_df, hp.TRAIN_VAL_TEST_SPLIT)\n",
    "dfs = [train_df, val_df, test_df]\n",
    "overlap = [True, True, False]\n",
    "\n",
    "set_names = ['train', 'val', 'test']\n",
    "results = {name: {} for name in set_names}\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    # Actual code\n",
    "    set_name = set_names[i]\n",
    "    strata_df = assign_strata(df)\n",
    "    samples_df, samples_strata_df = create_samples(df, strata_df, window_size, set_name, overlap=overlap[i])\n",
    "\n",
    "    print(f'Samples created from {set_name} set:', len(samples_df))\n",
    "    #if len(samples_df) > 0:\n",
    "        #print(f'Sample start times in {set_name} set (first 10):', samples_df.index[:10])\n",
    "\n",
    "    #print(f'Samples per strata in {set_name} set: {samples_strata_df[\"strata\"].value_counts()}')'train', 'val', 'test']\n",
    "results = {name: {} for name in set_names}\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    # Actual code\n",
    "    set_name = set_names[i]\n",
    "    strata_df = assign_strata(df)\n",
    "    samples_df, samples_strata_df = create_samples(df, strata_df, window_size, set_name, overlap=overlap[i])\n",
    "\n",
    "    print(f'Samples created from {set_name} set:', len(samples_df))\n",
    "    #if len(samples_df) > 0:\n",
    "        #print(f'Sample start times in {set_name} set (first 10):', samples_df.index[:10])\n",
    "\n",
    "    #print(f'Samples per strata in {set_name} set: {samples_strata_df[\"strata\"].value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48088a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows per month: year_month\n",
      "2020-01    2976\n",
      "2020-02    2699\n",
      "2020-03    2976\n",
      "2020-04    2756\n",
      "2020-05    1581\n",
      "2020-06    2067\n",
      "2020-07    2147\n",
      "2020-08    2098\n",
      "2020-09    1522\n",
      "2020-10     200\n",
      "2020-11     985\n",
      "2020-12    1157\n",
      "2021-01    2361\n",
      "2021-02    2688\n",
      "2021-03    2976\n",
      "2021-04    2880\n",
      "2021-05     457\n",
      "2022-02     584\n",
      "2022-03    2029\n",
      "2023-05    2195\n",
      "2023-06    2817\n",
      "2023-07    2221\n",
      "2023-08    2884\n",
      "2023-09    2796\n",
      "2023-10    2757\n",
      "2023-11    2354\n",
      "2023-12    2549\n",
      "2024-01    1969\n",
      "2024-02    2519\n",
      "2024-03    2698\n",
      "2024-04    1885\n",
      "2024-05    2804\n",
      "2024-06    2317\n",
      "2024-07    2495\n",
      "2024-08    1220\n",
      "2024-09     459\n",
      "Freq: M, Name: count, dtype: int64\n",
      "\n",
      "Gap summary for train set:\n",
      "Gap before 2020-03-01 00:00:00: 29 days 00:15:00 (from 2020-01-31 23:45:00 to 2020-03-01 00:00:00)\n",
      "Gap before 2020-04-29 23:00:00: 0 days 08:15:00 (from 2020-04-29 14:45:00 to 2020-04-29 23:00:00)\n",
      "Gap before 2020-04-30 23:00:00: 0 days 23:15:00 (from 2020-04-29 23:45:00 to 2020-04-30 23:00:00)\n",
      "Gap before 2020-05-01 23:00:00: 0 days 23:15:00 (from 2020-04-30 23:45:00 to 2020-05-01 23:00:00)\n",
      "Gap before 2020-05-02 23:00:00: 0 days 23:15:00 (from 2020-05-01 23:45:00 to 2020-05-02 23:00:00)\n",
      "Gap before 2020-05-03 23:00:00: 0 days 23:15:00 (from 2020-05-02 23:45:00 to 2020-05-03 23:00:00)\n",
      "Gap before 2020-05-04 23:00:00: 0 days 23:15:00 (from 2020-05-03 23:45:00 to 2020-05-04 23:00:00)\n",
      "Gap before 2020-05-06 23:00:00: 0 days 13:00:00 (from 2020-05-06 10:00:00 to 2020-05-06 23:00:00)\n",
      "Gap before 2020-05-07 23:00:00: 0 days 23:15:00 (from 2020-05-06 23:45:00 to 2020-05-07 23:00:00)\n",
      "Gap before 2020-05-08 23:00:00: 0 days 11:00:00 (from 2020-05-08 12:00:00 to 2020-05-08 23:00:00)\n",
      "Gap before 2020-05-09 23:00:00: 0 days 23:15:00 (from 2020-05-08 23:45:00 to 2020-05-09 23:00:00)\n",
      "Gap before 2020-05-10 23:00:00: 0 days 23:15:00 (from 2020-05-09 23:45:00 to 2020-05-10 23:00:00)\n",
      "Gap before 2020-05-11 23:00:00: 0 days 23:15:00 (from 2020-05-10 23:45:00 to 2020-05-11 23:00:00)\n",
      "Gap before 2020-05-13 23:00:00: 0 days 13:00:00 (from 2020-05-13 10:00:00 to 2020-05-13 23:00:00)\n",
      "Gap before 2020-05-14 23:00:00: 0 days 23:15:00 (from 2020-05-13 23:45:00 to 2020-05-14 23:00:00)\n",
      "Gap before 2020-05-15 23:00:00: 0 days 11:00:00 (from 2020-05-15 12:00:00 to 2020-05-15 23:00:00)\n",
      "Gap before 2020-05-16 23:00:00: 0 days 23:15:00 (from 2020-05-15 23:45:00 to 2020-05-16 23:00:00)\n",
      "Gap before 2020-05-17 23:00:00: 0 days 23:15:00 (from 2020-05-16 23:45:00 to 2020-05-17 23:00:00)\n",
      "Gap before 2020-05-18 23:00:00: 0 days 23:15:00 (from 2020-05-17 23:45:00 to 2020-05-18 23:00:00)\n",
      "Gap before 2020-05-20 23:00:00: 0 days 13:00:00 (from 2020-05-20 10:00:00 to 2020-05-20 23:00:00)\n",
      "Gap before 2020-05-21 13:00:00: 0 days 13:15:00 (from 2020-05-20 23:45:00 to 2020-05-21 13:00:00)\n",
      "Gap before 2020-06-12 03:15:00: 0 days 16:30:00 (from 2020-06-11 10:45:00 to 2020-06-12 03:15:00)\n",
      "Gap before 2020-06-19 23:00:00: 0 days 12:30:00 (from 2020-06-19 10:30:00 to 2020-06-19 23:00:00)\n",
      "Gap before 2020-06-20 23:00:00: 0 days 23:15:00 (from 2020-06-19 23:45:00 to 2020-06-20 23:00:00)\n",
      "Gap before 2020-06-21 23:00:00: 0 days 23:15:00 (from 2020-06-20 23:45:00 to 2020-06-21 23:00:00)\n",
      "Gap before 2020-06-22 23:00:00: 0 days 12:30:00 (from 2020-06-22 10:30:00 to 2020-06-22 23:00:00)\n",
      "Gap before 2020-06-23 23:00:00: 0 days 12:15:00 (from 2020-06-23 10:45:00 to 2020-06-23 23:00:00)\n",
      "Gap before 2020-06-24 23:00:00: 0 days 12:30:00 (from 2020-06-24 10:30:00 to 2020-06-24 23:00:00)\n",
      "Gap before 2020-06-25 09:45:00: 0 days 10:00:00 (from 2020-06-24 23:45:00 to 2020-06-25 09:45:00)\n",
      "Gap before 2020-06-26 23:00:00: 0 days 12:30:00 (from 2020-06-26 10:30:00 to 2020-06-26 23:00:00)\n",
      "Gap before 2020-06-27 23:00:00: 0 days 23:15:00 (from 2020-06-26 23:45:00 to 2020-06-27 23:00:00)\n",
      "Gap before 2020-06-28 23:00:00: 0 days 23:15:00 (from 2020-06-27 23:45:00 to 2020-06-28 23:00:00)\n",
      "Gap before 2020-06-29 23:00:00: 0 days 12:30:00 (from 2020-06-29 10:30:00 to 2020-06-29 23:00:00)\n",
      "Gap before 2020-06-30 23:00:00: 0 days 12:15:00 (from 2020-06-30 10:45:00 to 2020-06-30 23:00:00)\n",
      "Gap before 2020-07-01 23:00:00: 0 days 12:30:00 (from 2020-07-01 10:30:00 to 2020-07-01 23:00:00)\n",
      "Gap before 2020-07-04 23:00:00: 0 days 12:30:00 (from 2020-07-04 10:30:00 to 2020-07-04 23:00:00)\n",
      "Gap before 2020-07-06 23:00:00: 0 days 12:30:00 (from 2020-07-06 10:30:00 to 2020-07-06 23:00:00)\n",
      "Gap before 2020-07-07 23:00:00: 0 days 12:15:00 (from 2020-07-07 10:45:00 to 2020-07-07 23:00:00)\n",
      "Gap before 2020-07-08 23:00:00: 0 days 12:30:00 (from 2020-07-08 10:30:00 to 2020-07-08 23:00:00)\n",
      "Gap before 2020-07-11 23:00:00: 0 days 12:30:00 (from 2020-07-11 10:30:00 to 2020-07-11 23:00:00)\n",
      "Gap before 2020-07-13 23:00:00: 0 days 12:30:00 (from 2020-07-13 10:30:00 to 2020-07-13 23:00:00)\n",
      "Gap before 2020-07-14 23:00:00: 0 days 12:15:00 (from 2020-07-14 10:45:00 to 2020-07-14 23:00:00)\n",
      "Gap before 2020-07-15 23:00:00: 0 days 12:30:00 (from 2020-07-15 10:30:00 to 2020-07-15 23:00:00)\n",
      "Gap before 2020-07-18 23:00:00: 0 days 12:30:00 (from 2020-07-18 10:30:00 to 2020-07-18 23:00:00)\n",
      "Gap before 2020-07-20 23:00:00: 0 days 12:30:00 (from 2020-07-20 10:30:00 to 2020-07-20 23:00:00)\n",
      "Gap before 2020-07-21 23:00:00: 0 days 12:15:00 (from 2020-07-21 10:45:00 to 2020-07-21 23:00:00)\n",
      "Gap before 2020-07-22 23:00:00: 0 days 12:30:00 (from 2020-07-22 10:30:00 to 2020-07-22 23:00:00)\n",
      "Gap before 2020-07-25 23:00:00: 0 days 12:30:00 (from 2020-07-25 10:30:00 to 2020-07-25 23:00:00)\n",
      "Gap before 2020-07-27 23:00:00: 0 days 12:30:00 (from 2020-07-27 10:30:00 to 2020-07-27 23:00:00)\n",
      "Gap before 2020-07-28 23:00:00: 0 days 12:15:00 (from 2020-07-28 10:45:00 to 2020-07-28 23:00:00)\n",
      "Gap before 2020-07-29 23:00:00: 0 days 12:30:00 (from 2020-07-29 10:30:00 to 2020-07-29 23:00:00)\n",
      "Gap before 2020-08-01 23:00:00: 0 days 12:30:00 (from 2020-08-01 10:30:00 to 2020-08-01 23:00:00)\n",
      "Gap before 2020-08-03 23:00:00: 0 days 12:30:00 (from 2020-08-03 10:30:00 to 2020-08-03 23:00:00)\n",
      "Gap before 2020-08-04 23:00:00: 0 days 12:15:00 (from 2020-08-04 10:45:00 to 2020-08-04 23:00:00)\n",
      "Gap before 2020-08-05 23:00:00: 0 days 12:30:00 (from 2020-08-05 10:30:00 to 2020-08-05 23:00:00)\n",
      "Gap before 2020-08-08 23:00:00: 0 days 12:30:00 (from 2020-08-08 10:30:00 to 2020-08-08 23:00:00)\n",
      "Gap before 2020-08-10 23:00:00: 0 days 12:30:00 (from 2020-08-10 10:30:00 to 2020-08-10 23:00:00)\n",
      "Gap before 2020-08-11 23:00:00: 0 days 12:15:00 (from 2020-08-11 10:45:00 to 2020-08-11 23:00:00)\n",
      "Gap before 2020-08-12 23:00:00: 0 days 12:30:00 (from 2020-08-12 10:30:00 to 2020-08-12 23:00:00)\n",
      "Gap before 2020-08-15 23:00:00: 0 days 12:30:00 (from 2020-08-15 10:30:00 to 2020-08-15 23:00:00)\n",
      "Gap before 2020-08-17 23:00:00: 0 days 12:30:00 (from 2020-08-17 10:30:00 to 2020-08-17 23:00:00)\n",
      "Gap before 2020-08-18 23:00:00: 0 days 12:15:00 (from 2020-08-18 10:45:00 to 2020-08-18 23:00:00)\n",
      "Gap before 2020-08-19 23:00:00: 0 days 12:30:00 (from 2020-08-19 10:30:00 to 2020-08-19 23:00:00)\n",
      "Gap before 2020-08-22 23:00:00: 0 days 12:30:00 (from 2020-08-22 10:30:00 to 2020-08-22 23:00:00)\n",
      "Gap before 2020-08-24 23:00:00: 0 days 12:30:00 (from 2020-08-24 10:30:00 to 2020-08-24 23:00:00)\n",
      "Gap before 2020-08-25 23:00:00: 0 days 12:15:00 (from 2020-08-25 10:45:00 to 2020-08-25 23:00:00)\n",
      "Gap before 2020-08-26 23:00:00: 0 days 12:30:00 (from 2020-08-26 10:30:00 to 2020-08-26 23:00:00)\n",
      "Gap before 2020-08-29 23:00:00: 0 days 12:30:00 (from 2020-08-29 10:30:00 to 2020-08-29 23:00:00)\n",
      "Gap before 2020-08-31 23:00:00: 0 days 12:30:00 (from 2020-08-31 10:30:00 to 2020-08-31 23:00:00)\n",
      "Gap before 2020-09-01 23:00:00: 0 days 12:15:00 (from 2020-09-01 10:45:00 to 2020-09-01 23:00:00)\n",
      "Gap before 2020-09-02 23:00:00: 0 days 12:30:00 (from 2020-09-02 10:30:00 to 2020-09-02 23:00:00)\n",
      "Gap before 2020-09-05 23:00:00: 0 days 12:30:00 (from 2020-09-05 10:30:00 to 2020-09-05 23:00:00)\n",
      "Gap before 2020-09-07 23:00:00: 0 days 12:30:00 (from 2020-09-07 10:30:00 to 2020-09-07 23:00:00)\n",
      "Gap before 2020-09-08 23:00:00: 0 days 12:15:00 (from 2020-09-08 10:45:00 to 2020-09-08 23:00:00)\n",
      "Gap before 2020-09-09 23:00:00: 0 days 12:30:00 (from 2020-09-09 10:30:00 to 2020-09-09 23:00:00)\n",
      "Gap before 2020-09-12 23:00:00: 0 days 12:30:00 (from 2020-09-12 10:30:00 to 2020-09-12 23:00:00)\n",
      "Gap before 2020-09-14 23:00:00: 0 days 12:30:00 (from 2020-09-14 10:30:00 to 2020-09-14 23:00:00)\n",
      "Gap before 2020-09-15 23:00:00: 0 days 12:15:00 (from 2020-09-15 10:45:00 to 2020-09-15 23:00:00)\n",
      "Gap before 2020-09-16 23:00:00: 0 days 12:30:00 (from 2020-09-16 10:30:00 to 2020-09-16 23:00:00)\n",
      "Gap before 2020-09-19 23:00:00: 0 days 12:30:00 (from 2020-09-19 10:30:00 to 2020-09-19 23:00:00)\n",
      "Gap before 2020-09-21 23:00:00: 0 days 12:30:00 (from 2020-09-21 10:30:00 to 2020-09-21 23:00:00)\n",
      "Gap before 2020-09-22 23:00:00: 0 days 12:15:00 (from 2020-09-22 10:45:00 to 2020-09-22 23:00:00)\n",
      "Gap before 2020-10-08 12:45:00: 15 days 02:15:00 (from 2020-09-23 10:30:00 to 2020-10-08 12:45:00)\n",
      "Gap before 2020-10-26 14:15:00: 18 days 01:30:00 (from 2020-10-08 12:45:00 to 2020-10-26 14:15:00)\n",
      "Gap before 2020-10-28 07:30:00: 0 days 10:30:00 (from 2020-10-27 21:00:00 to 2020-10-28 07:30:00)\n",
      "Gap before 2020-11-12 13:15:00: 14 days 11:15:00 (from 2020-10-29 02:00:00 to 2020-11-12 13:15:00)\n",
      "Gap before 2020-11-24 13:30:00: 8 days 04:45:00 (from 2020-11-16 08:45:00 to 2020-11-24 13:30:00)\n",
      "Gap before 2021-03-01 00:00:00: 77 days 23:00:00 (from 2020-12-13 01:00:00 to 2021-03-01 00:00:00)\n",
      "Gap before 2022-02-21 00:00:00: 296 days 00:15:00 (from 2021-04-30 23:45:00 to 2022-02-21 00:00:00)\n",
      "Gap before 2022-02-24 23:00:00: 0 days 23:15:00 (from 2022-02-23 23:45:00 to 2022-02-24 23:00:00)\n",
      "Gap before 2022-02-25 23:00:00: 0 days 23:15:00 (from 2022-02-24 23:45:00 to 2022-02-25 23:00:00)\n",
      "Gap before 2022-03-03 23:00:00: 0 days 23:15:00 (from 2022-03-02 23:45:00 to 2022-03-03 23:00:00)\n",
      "Gap before 2022-03-04 23:00:00: 0 days 23:15:00 (from 2022-03-03 23:45:00 to 2022-03-04 23:00:00)\n",
      "Gap before 2022-03-10 23:00:00: 0 days 23:15:00 (from 2022-03-09 23:45:00 to 2022-03-10 23:00:00)\n",
      "Gap before 2022-03-11 23:00:00: 0 days 23:15:00 (from 2022-03-10 23:45:00 to 2022-03-11 23:00:00)\n",
      "Gap before 2022-03-17 23:00:00: 0 days 23:15:00 (from 2022-03-16 23:45:00 to 2022-03-17 23:00:00)\n",
      "Gap before 2022-03-18 23:00:00: 0 days 23:15:00 (from 2022-03-17 23:45:00 to 2022-03-18 23:00:00)\n",
      "Gap before 2022-03-24 23:00:00: 0 days 23:15:00 (from 2022-03-23 23:45:00 to 2022-03-24 23:00:00)\n",
      "Gap before 2022-03-25 23:00:00: 0 days 23:15:00 (from 2022-03-24 23:45:00 to 2022-03-25 23:00:00)\n",
      "Gap before 2023-05-02 10:00:00: 398 days 15:00:00 (from 2022-03-29 19:00:00 to 2023-05-02 10:00:00)\n",
      "Gap before 2023-05-10 23:00:00: 0 days 11:15:00 (from 2023-05-10 11:45:00 to 2023-05-10 23:00:00)\n",
      "Gap before 2023-05-11 23:00:00: 0 days 23:15:00 (from 2023-05-10 23:45:00 to 2023-05-11 23:00:00)\n",
      "Gap before 2023-05-12 23:00:00: 0 days 23:15:00 (from 2023-05-11 23:45:00 to 2023-05-12 23:00:00)\n",
      "Gap before 2023-05-13 23:00:00: 0 days 23:15:00 (from 2023-05-12 23:45:00 to 2023-05-13 23:00:00)\n",
      "Gap before 2023-05-14 23:00:00: 0 days 23:15:00 (from 2023-05-13 23:45:00 to 2023-05-14 23:00:00)\n",
      "Gap before 2023-05-15 23:00:00: 0 days 23:15:00 (from 2023-05-14 23:45:00 to 2023-05-15 23:00:00)\n",
      "Gap before 2023-05-16 23:00:00: 0 days 23:15:00 (from 2023-05-15 23:45:00 to 2023-05-16 23:00:00)\n",
      "Gap before 2023-05-17 12:15:00: 0 days 12:30:00 (from 2023-05-16 23:45:00 to 2023-05-17 12:15:00)\n",
      "Gap before 2023-06-19 15:45:00: 0 days 16:00:00 (from 2023-06-18 23:45:00 to 2023-06-19 15:45:00)\n",
      "Gap before 2023-07-03 14:15:00: 0 days 14:30:00 (from 2023-07-02 23:45:00 to 2023-07-03 14:15:00)\n",
      "Gap before 2023-07-05 16:30:00: 0 days 17:45:00 (from 2023-07-04 22:45:00 to 2023-07-05 16:30:00)\n",
      "Gap before 2023-07-06 19:45:00: 0 days 21:00:00 (from 2023-07-05 22:45:00 to 2023-07-06 19:45:00)\n",
      "Gap before 2023-07-08 23:00:00: 0 days 23:15:00 (from 2023-07-07 23:45:00 to 2023-07-08 23:00:00)\n",
      "Gap before 2023-07-10 23:00:00: 1 days 17:00:00 (from 2023-07-09 06:00:00 to 2023-07-10 23:00:00)\n",
      "Gap before 2023-07-12 23:00:00: 1 days 00:15:00 (from 2023-07-11 22:45:00 to 2023-07-12 23:00:00)\n",
      "Gap before 2023-07-14 23:00:00: 1 days 00:15:00 (from 2023-07-13 22:45:00 to 2023-07-14 23:00:00)\n",
      "Gap before 2023-07-16 23:00:00: 0 days 13:15:00 (from 2023-07-16 09:45:00 to 2023-07-16 23:00:00)\n",
      "Gap before 2023-07-31 18:15:00: 0 days 10:15:00 (from 2023-07-31 08:00:00 to 2023-07-31 18:15:00)\n",
      "Gap before 2023-09-01 00:00:00: 31 days 01:45:00 (from 2023-07-31 22:15:00 to 2023-09-01 00:00:00)\n",
      "Gap before 2023-09-27 20:00:00: 0 days 21:15:00 (from 2023-09-26 22:45:00 to 2023-09-27 20:00:00)\n",
      "Gap before 2023-10-01 23:00:00: 0 days 08:15:00 (from 2023-10-01 14:45:00 to 2023-10-01 23:00:00)\n",
      "Gap before 2023-10-10 18:30:00: 0 days 23:45:00 (from 2023-10-09 18:45:00 to 2023-10-10 18:30:00)\n",
      "Gap before 2023-10-12 11:30:00: 0 days 12:45:00 (from 2023-10-11 22:45:00 to 2023-10-12 11:30:00)\n",
      "Gap before 2023-10-15 23:00:00: 0 days 11:00:00 (from 2023-10-15 12:00:00 to 2023-10-15 23:00:00)\n",
      "Gap before 2023-11-06 15:45:00: 0 days 16:00:00 (from 2023-11-05 23:45:00 to 2023-11-06 15:45:00)\n",
      "Gap before 2023-11-16 00:00:00: 1 days 00:15:00 (from 2023-11-14 23:45:00 to 2023-11-16 00:00:00)\n",
      "Gap before 2023-11-30 00:00:00: 3 days 20:00:00 (from 2023-11-26 04:00:00 to 2023-11-30 00:00:00)\n",
      "Gap before 2024-01-01 00:00:00: 31 days 00:15:00 (from 2023-11-30 23:45:00 to 2024-01-01 00:00:00)\n",
      "Gap before 2024-01-15 00:00:00: 10 days 12:00:00 (from 2024-01-04 12:00:00 to 2024-01-15 00:00:00)\n",
      "Gap before 2024-04-01 00:00:00: 60 days 00:15:00 (from 2024-01-31 23:45:00 to 2024-04-01 00:00:00)\n",
      "Gap before 2024-04-11 22:30:00: 0 days 09:45:00 (from 2024-04-11 12:45:00 to 2024-04-11 22:30:00)\n",
      "Gap before 2024-04-16 23:00:00: 0 days 23:15:00 (from 2024-04-15 23:45:00 to 2024-04-16 23:00:00)\n",
      "Gap before 2024-04-17 23:00:00: 0 days 23:15:00 (from 2024-04-16 23:45:00 to 2024-04-17 23:00:00)\n",
      "Gap before 2024-04-18 23:00:00: 0 days 23:15:00 (from 2024-04-17 23:45:00 to 2024-04-18 23:00:00)\n",
      "Gap before 2024-04-19 23:00:00: 0 days 23:15:00 (from 2024-04-18 23:45:00 to 2024-04-19 23:00:00)\n",
      "Gap before 2024-04-21 23:00:00: 0 days 23:15:00 (from 2024-04-20 23:45:00 to 2024-04-21 23:00:00)\n",
      "Gap before 2024-04-22 23:00:00: 0 days 23:15:00 (from 2024-04-21 23:45:00 to 2024-04-22 23:00:00)\n",
      "Gap before 2024-04-23 21:45:00: 0 days 13:00:00 (from 2024-04-23 08:45:00 to 2024-04-23 21:45:00)\n",
      "Gap before 2024-04-24 23:00:00: 0 days 17:15:00 (from 2024-04-24 05:45:00 to 2024-04-24 23:00:00)\n",
      "Gap before 2024-04-25 09:45:00: 0 days 10:00:00 (from 2024-04-24 23:45:00 to 2024-04-25 09:45:00)\n",
      "Gap before 2024-04-26 23:00:00: 0 days 16:00:00 (from 2024-04-26 07:00:00 to 2024-04-26 23:00:00)\n",
      "Gap before 2024-04-28 23:00:00: 0 days 23:15:00 (from 2024-04-27 23:45:00 to 2024-04-28 23:00:00)\n",
      "Gap before 2024-04-30 23:00:00: 0 days 23:15:00 (from 2024-04-29 23:45:00 to 2024-04-30 23:00:00)\n",
      "Gap before 2024-06-01 00:00:00: 31 days 00:15:00 (from 2024-04-30 23:45:00 to 2024-06-01 00:00:00)\n",
      "Gap before 2024-06-07 23:00:00: 3 days 12:00:00 (from 2024-06-04 11:00:00 to 2024-06-07 23:00:00)\n",
      "Gap before 2024-06-08 23:00:00: 0 days 23:15:00 (from 2024-06-07 23:45:00 to 2024-06-08 23:00:00)\n",
      "Gap before 2024-06-10 09:00:00: 1 days 09:15:00 (from 2024-06-08 23:45:00 to 2024-06-10 09:00:00)\n",
      "Gap before 2024-08-01 00:00:00: 31 days 01:15:00 (from 2024-06-30 22:45:00 to 2024-08-01 00:00:00)\n",
      "Gap before 2024-08-13 23:00:00: 0 days 23:15:00 (from 2024-08-12 23:45:00 to 2024-08-13 23:00:00)\n",
      "Gap before 2024-08-14 23:00:00: 0 days 23:15:00 (from 2024-08-13 23:45:00 to 2024-08-14 23:00:00)\n",
      "Gap before 2024-08-15 23:00:00: 0 days 23:15:00 (from 2024-08-14 23:45:00 to 2024-08-15 23:00:00)\n",
      "Gap before 2024-08-18 23:00:00: 2 days 23:15:00 (from 2024-08-15 23:45:00 to 2024-08-18 23:00:00)\n",
      "Gap before 2024-08-19 23:00:00: 0 days 23:15:00 (from 2024-08-18 23:45:00 to 2024-08-19 23:00:00)\n",
      "Gap before 2024-08-20 23:00:00: 0 days 23:15:00 (from 2024-08-19 23:45:00 to 2024-08-20 23:00:00)\n",
      "Gap before 2024-08-21 23:00:00: 0 days 23:15:00 (from 2024-08-20 23:45:00 to 2024-08-21 23:00:00)\n",
      "Gap before 2024-08-22 23:00:00: 0 days 23:15:00 (from 2024-08-21 23:45:00 to 2024-08-22 23:00:00)\n",
      "Gap before 2024-08-23 23:00:00: 0 days 23:15:00 (from 2024-08-22 23:45:00 to 2024-08-23 23:00:00)\n",
      "Gap before 2024-08-24 23:00:00: 0 days 23:15:00 (from 2024-08-23 23:45:00 to 2024-08-24 23:00:00)\n",
      "Gap before 2024-08-25 23:00:00: 0 days 23:15:00 (from 2024-08-24 23:45:00 to 2024-08-25 23:00:00)\n",
      "Gap before 2024-08-26 23:00:00: 0 days 23:15:00 (from 2024-08-25 23:45:00 to 2024-08-26 23:00:00)\n",
      "Gap before 2024-08-27 23:00:00: 0 days 23:15:00 (from 2024-08-26 23:45:00 to 2024-08-27 23:00:00)\n",
      "Gap before 2024-08-28 23:00:00: 0 days 23:15:00 (from 2024-08-27 23:45:00 to 2024-08-28 23:00:00)\n",
      "Gap before 2024-08-29 23:00:00: 0 days 23:15:00 (from 2024-08-28 23:45:00 to 2024-08-29 23:00:00)\n",
      "Gap before 2024-08-30 23:00:00: 0 days 23:15:00 (from 2024-08-29 23:45:00 to 2024-08-30 23:00:00)\n",
      "Gap before 2024-08-31 23:00:00: 0 days 23:15:00 (from 2024-08-30 23:45:00 to 2024-08-31 23:00:00)\n",
      "Segments in train set: 166\n",
      "Processing segment 0 in train set, length: 2976, from 2020-01-01 00:00:00 to 2020-01-31 23:45:00\n",
      "Created 12\n",
      "Processing segment 1 in train set, length: 5724, from 2020-03-01 00:00:00 to 2020-04-29 14:45:00\n",
      "Created 25\n",
      "Processing segment 2 in train set, length: 4, from 2020-04-29 23:00:00 to 2020-04-29 23:45:00\n",
      "Created 0\n",
      "Processing segment 3 in train set, length: 4, from 2020-04-30 23:00:00 to 2020-04-30 23:45:00\n",
      "Created 0\n",
      "Processing segment 4 in train set, length: 4, from 2020-05-01 23:00:00 to 2020-05-01 23:45:00\n",
      "Created 0\n",
      "Processing segment 5 in train set, length: 4, from 2020-05-02 23:00:00 to 2020-05-02 23:45:00\n",
      "Created 0\n",
      "Processing segment 6 in train set, length: 4, from 2020-05-03 23:00:00 to 2020-05-03 23:45:00\n",
      "Created 0\n",
      "Processing segment 7 in train set, length: 141, from 2020-05-04 23:00:00 to 2020-05-06 10:00:00\n",
      "Created 0\n",
      "Processing segment 8 in train set, length: 4, from 2020-05-06 23:00:00 to 2020-05-06 23:45:00\n",
      "Created 0\n",
      "Processing segment 9 in train set, length: 53, from 2020-05-07 23:00:00 to 2020-05-08 12:00:00\n",
      "Created 0\n",
      "Processing segment 10 in train set, length: 4, from 2020-05-08 23:00:00 to 2020-05-08 23:45:00\n",
      "Created 0\n",
      "Processing segment 11 in train set, length: 4, from 2020-05-09 23:00:00 to 2020-05-09 23:45:00\n",
      "Created 0\n",
      "Processing segment 12 in train set, length: 4, from 2020-05-10 23:00:00 to 2020-05-10 23:45:00\n",
      "Created 0\n",
      "Processing segment 13 in train set, length: 141, from 2020-05-11 23:00:00 to 2020-05-13 10:00:00\n",
      "Created 0\n",
      "Processing segment 14 in train set, length: 4, from 2020-05-13 23:00:00 to 2020-05-13 23:45:00\n",
      "Created 0\n",
      "Processing segment 15 in train set, length: 53, from 2020-05-14 23:00:00 to 2020-05-15 12:00:00\n",
      "Created 0\n",
      "Processing segment 16 in train set, length: 4, from 2020-05-15 23:00:00 to 2020-05-15 23:45:00\n",
      "Created 0\n",
      "Processing segment 17 in train set, length: 4, from 2020-05-16 23:00:00 to 2020-05-16 23:45:00\n",
      "Created 0\n",
      "Processing segment 18 in train set, length: 4, from 2020-05-17 23:00:00 to 2020-05-17 23:45:00\n",
      "Created 0\n",
      "Processing segment 19 in train set, length: 141, from 2020-05-18 23:00:00 to 2020-05-20 10:00:00\n",
      "Created 0\n",
      "Processing segment 20 in train set, length: 4, from 2020-05-20 23:00:00 to 2020-05-20 23:45:00\n",
      "Created 0\n",
      "Processing segment 21 in train set, length: 2008, from 2020-05-21 13:00:00 to 2020-06-11 10:45:00\n",
      "Created 8\n",
      "Processing segment 22 in train set, length: 702, from 2020-06-12 03:15:00 to 2020-06-19 10:30:00\n",
      "Created 2\n",
      "Processing segment 23 in train set, length: 4, from 2020-06-19 23:00:00 to 2020-06-19 23:45:00\n",
      "Created 0\n",
      "Processing segment 24 in train set, length: 4, from 2020-06-20 23:00:00 to 2020-06-20 23:45:00\n",
      "Created 0\n",
      "Processing segment 25 in train set, length: 47, from 2020-06-21 23:00:00 to 2020-06-22 10:30:00\n",
      "Created 0\n",
      "Processing segment 26 in train set, length: 48, from 2020-06-22 23:00:00 to 2020-06-23 10:45:00\n",
      "Created 0\n",
      "Processing segment 27 in train set, length: 47, from 2020-06-23 23:00:00 to 2020-06-24 10:30:00\n",
      "Created 0\n",
      "Processing segment 28 in train set, length: 4, from 2020-06-24 23:00:00 to 2020-06-24 23:45:00\n",
      "Created 0\n",
      "Processing segment 29 in train set, length: 100, from 2020-06-25 09:45:00 to 2020-06-26 10:30:00\n",
      "Created 0\n",
      "Processing segment 30 in train set, length: 4, from 2020-06-26 23:00:00 to 2020-06-26 23:45:00\n",
      "Created 0\n",
      "Processing segment 31 in train set, length: 4, from 2020-06-27 23:00:00 to 2020-06-27 23:45:00\n",
      "Created 0\n",
      "Processing segment 32 in train set, length: 47, from 2020-06-28 23:00:00 to 2020-06-29 10:30:00\n",
      "Created 0\n",
      "Processing segment 33 in train set, length: 48, from 2020-06-29 23:00:00 to 2020-06-30 10:45:00\n",
      "Created 0\n",
      "Processing segment 34 in train set, length: 47, from 2020-06-30 23:00:00 to 2020-07-01 10:30:00\n",
      "Created 0\n",
      "Processing segment 35 in train set, length: 239, from 2020-07-01 23:00:00 to 2020-07-04 10:30:00\n",
      "Created 0\n",
      "Processing segment 36 in train set, length: 143, from 2020-07-04 23:00:00 to 2020-07-06 10:30:00\n",
      "Created 0\n",
      "Processing segment 37 in train set, length: 48, from 2020-07-06 23:00:00 to 2020-07-07 10:45:00\n",
      "Created 0\n",
      "Processing segment 38 in train set, length: 47, from 2020-07-07 23:00:00 to 2020-07-08 10:30:00\n",
      "Created 0\n",
      "Processing segment 39 in train set, length: 239, from 2020-07-08 23:00:00 to 2020-07-11 10:30:00\n",
      "Created 0\n",
      "Processing segment 40 in train set, length: 143, from 2020-07-11 23:00:00 to 2020-07-13 10:30:00\n",
      "Created 0\n",
      "Processing segment 41 in train set, length: 48, from 2020-07-13 23:00:00 to 2020-07-14 10:45:00\n",
      "Created 0\n",
      "Processing segment 42 in train set, length: 47, from 2020-07-14 23:00:00 to 2020-07-15 10:30:00\n",
      "Created 0\n",
      "Processing segment 43 in train set, length: 239, from 2020-07-15 23:00:00 to 2020-07-18 10:30:00\n",
      "Created 0\n",
      "Processing segment 44 in train set, length: 143, from 2020-07-18 23:00:00 to 2020-07-20 10:30:00\n",
      "Created 0\n",
      "Processing segment 45 in train set, length: 48, from 2020-07-20 23:00:00 to 2020-07-21 10:45:00\n",
      "Created 0\n",
      "Processing segment 46 in train set, length: 47, from 2020-07-21 23:00:00 to 2020-07-22 10:30:00\n",
      "Created 0\n",
      "Processing segment 47 in train set, length: 239, from 2020-07-22 23:00:00 to 2020-07-25 10:30:00\n",
      "Created 0\n",
      "Processing segment 48 in train set, length: 143, from 2020-07-25 23:00:00 to 2020-07-27 10:30:00\n",
      "Created 0\n",
      "Processing segment 49 in train set, length: 48, from 2020-07-27 23:00:00 to 2020-07-28 10:45:00\n",
      "Created 0\n",
      "Processing segment 50 in train set, length: 47, from 2020-07-28 23:00:00 to 2020-07-29 10:30:00\n",
      "Created 0\n",
      "Processing segment 51 in train set, length: 239, from 2020-07-29 23:00:00 to 2020-08-01 10:30:00\n",
      "Created 0\n",
      "Processing segment 52 in train set, length: 143, from 2020-08-01 23:00:00 to 2020-08-03 10:30:00\n",
      "Created 0\n",
      "Processing segment 53 in train set, length: 48, from 2020-08-03 23:00:00 to 2020-08-04 10:45:00\n",
      "Created 0\n",
      "Processing segment 54 in train set, length: 47, from 2020-08-04 23:00:00 to 2020-08-05 10:30:00\n",
      "Created 0\n",
      "Processing segment 55 in train set, length: 239, from 2020-08-05 23:00:00 to 2020-08-08 10:30:00\n",
      "Created 0\n",
      "Processing segment 56 in train set, length: 143, from 2020-08-08 23:00:00 to 2020-08-10 10:30:00\n",
      "Created 0\n",
      "Processing segment 57 in train set, length: 48, from 2020-08-10 23:00:00 to 2020-08-11 10:45:00\n",
      "Created 0\n",
      "Processing segment 58 in train set, length: 47, from 2020-08-11 23:00:00 to 2020-08-12 10:30:00\n",
      "Created 0\n",
      "Processing segment 59 in train set, length: 239, from 2020-08-12 23:00:00 to 2020-08-15 10:30:00\n",
      "Created 0\n",
      "Processing segment 60 in train set, length: 143, from 2020-08-15 23:00:00 to 2020-08-17 10:30:00\n",
      "Created 0\n",
      "Processing segment 61 in train set, length: 48, from 2020-08-17 23:00:00 to 2020-08-18 10:45:00\n",
      "Created 0\n",
      "Processing segment 62 in train set, length: 47, from 2020-08-18 23:00:00 to 2020-08-19 10:30:00\n",
      "Created 0\n",
      "Processing segment 63 in train set, length: 239, from 2020-08-19 23:00:00 to 2020-08-22 10:30:00\n",
      "Created 0\n",
      "Processing segment 64 in train set, length: 143, from 2020-08-22 23:00:00 to 2020-08-24 10:30:00\n",
      "Created 0\n",
      "Processing segment 65 in train set, length: 48, from 2020-08-24 23:00:00 to 2020-08-25 10:45:00\n",
      "Created 0\n",
      "Processing segment 66 in train set, length: 47, from 2020-08-25 23:00:00 to 2020-08-26 10:30:00\n",
      "Created 0\n",
      "Processing segment 67 in train set, length: 239, from 2020-08-26 23:00:00 to 2020-08-29 10:30:00\n",
      "Created 0\n",
      "Processing segment 68 in train set, length: 143, from 2020-08-29 23:00:00 to 2020-08-31 10:30:00\n",
      "Created 0\n",
      "Processing segment 69 in train set, length: 48, from 2020-08-31 23:00:00 to 2020-09-01 10:45:00\n",
      "Created 0\n",
      "Processing segment 70 in train set, length: 47, from 2020-09-01 23:00:00 to 2020-09-02 10:30:00\n",
      "Created 0\n",
      "Processing segment 71 in train set, length: 239, from 2020-09-02 23:00:00 to 2020-09-05 10:30:00\n",
      "Created 0\n",
      "Processing segment 72 in train set, length: 143, from 2020-09-05 23:00:00 to 2020-09-07 10:30:00\n",
      "Created 0\n",
      "Processing segment 73 in train set, length: 48, from 2020-09-07 23:00:00 to 2020-09-08 10:45:00\n",
      "Created 0\n",
      "Processing segment 74 in train set, length: 47, from 2020-09-08 23:00:00 to 2020-09-09 10:30:00\n",
      "Created 0\n",
      "Processing segment 75 in train set, length: 239, from 2020-09-09 23:00:00 to 2020-09-12 10:30:00\n",
      "Created 0\n",
      "Processing segment 76 in train set, length: 143, from 2020-09-12 23:00:00 to 2020-09-14 10:30:00\n",
      "Created 0\n",
      "Processing segment 77 in train set, length: 48, from 2020-09-14 23:00:00 to 2020-09-15 10:45:00\n",
      "Created 0\n",
      "Processing segment 78 in train set, length: 47, from 2020-09-15 23:00:00 to 2020-09-16 10:30:00\n",
      "Created 0\n",
      "Processing segment 79 in train set, length: 239, from 2020-09-16 23:00:00 to 2020-09-19 10:30:00\n",
      "Created 0\n",
      "Processing segment 80 in train set, length: 143, from 2020-09-19 23:00:00 to 2020-09-21 10:30:00\n",
      "Created 0\n",
      "Processing segment 81 in train set, length: 48, from 2020-09-21 23:00:00 to 2020-09-22 10:45:00\n",
      "Created 0\n",
      "Processing segment 82 in train set, length: 47, from 2020-09-22 23:00:00 to 2020-09-23 10:30:00\n",
      "Created 0\n",
      "Processing segment 83 in train set, length: 1, from 2020-10-08 12:45:00 to 2020-10-08 12:45:00\n",
      "Created 0\n",
      "Processing segment 84 in train set, length: 124, from 2020-10-26 14:15:00 to 2020-10-27 21:00:00\n",
      "Created 0\n",
      "Processing segment 85 in train set, length: 75, from 2020-10-28 07:30:00 to 2020-10-29 02:00:00\n",
      "Created 0\n",
      "Processing segment 86 in train set, length: 367, from 2020-11-12 13:15:00 to 2020-11-16 08:45:00\n",
      "Created 0\n",
      "Processing segment 87 in train set, length: 1775, from 2020-11-24 13:30:00 to 2020-12-13 01:00:00\n",
      "Created 7\n",
      "Processing segment 88 in train set, length: 5856, from 2021-03-01 00:00:00 to 2021-04-30 23:45:00\n",
      "Created 26\n",
      "Processing segment 89 in train set, length: 288, from 2022-02-21 00:00:00 to 2022-02-23 23:45:00\n",
      "Created 0\n",
      "Processing segment 90 in train set, length: 4, from 2022-02-24 23:00:00 to 2022-02-24 23:45:00\n",
      "Created 0\n",
      "Processing segment 91 in train set, length: 484, from 2022-02-25 23:00:00 to 2022-03-02 23:45:00\n",
      "Created 1\n",
      "Processing segment 92 in train set, length: 4, from 2022-03-03 23:00:00 to 2022-03-03 23:45:00\n",
      "Created 0\n",
      "Processing segment 93 in train set, length: 484, from 2022-03-04 23:00:00 to 2022-03-09 23:45:00\n",
      "Created 1\n",
      "Processing segment 94 in train set, length: 4, from 2022-03-10 23:00:00 to 2022-03-10 23:45:00\n",
      "Created 0\n",
      "Processing segment 95 in train set, length: 484, from 2022-03-11 23:00:00 to 2022-03-16 23:45:00\n",
      "Created 1\n",
      "Processing segment 96 in train set, length: 4, from 2022-03-17 23:00:00 to 2022-03-17 23:45:00\n",
      "Created 0\n",
      "Processing segment 97 in train set, length: 484, from 2022-03-18 23:00:00 to 2022-03-23 23:45:00\n",
      "Created 1\n",
      "Processing segment 98 in train set, length: 4, from 2022-03-24 23:00:00 to 2022-03-24 23:45:00\n",
      "Created 0\n",
      "Processing segment 99 in train set, length: 369, from 2022-03-25 23:00:00 to 2022-03-29 19:00:00\n",
      "Created 0\n",
      "Processing segment 100 in train set, length: 776, from 2023-05-02 10:00:00 to 2023-05-10 11:45:00\n",
      "Created 2\n",
      "Processing segment 101 in train set, length: 4, from 2023-05-10 23:00:00 to 2023-05-10 23:45:00\n",
      "Created 0\n",
      "Processing segment 102 in train set, length: 4, from 2023-05-11 23:00:00 to 2023-05-11 23:45:00\n",
      "Created 0\n",
      "Processing segment 103 in train set, length: 4, from 2023-05-12 23:00:00 to 2023-05-12 23:45:00\n",
      "Created 0\n",
      "Processing segment 104 in train set, length: 4, from 2023-05-13 23:00:00 to 2023-05-13 23:45:00\n",
      "Created 0\n",
      "Processing segment 105 in train set, length: 4, from 2023-05-14 23:00:00 to 2023-05-14 23:45:00\n",
      "Created 0\n",
      "Processing segment 106 in train set, length: 4, from 2023-05-15 23:00:00 to 2023-05-15 23:45:00\n",
      "Created 0\n",
      "Processing segment 107 in train set, length: 4, from 2023-05-16 23:00:00 to 2023-05-16 23:45:00\n",
      "Created 0\n",
      "Processing segment 108 in train set, length: 3119, from 2023-05-17 12:15:00 to 2023-06-18 23:45:00\n",
      "Created 13\n",
      "Processing segment 109 in train set, length: 1281, from 2023-06-19 15:45:00 to 2023-07-02 23:45:00\n",
      "Created 4\n",
      "Processing segment 110 in train set, length: 131, from 2023-07-03 14:15:00 to 2023-07-04 22:45:00\n",
      "Created 0\n",
      "Processing segment 111 in train set, length: 26, from 2023-07-05 16:30:00 to 2023-07-05 22:45:00\n",
      "Created 0\n",
      "Processing segment 112 in train set, length: 113, from 2023-07-06 19:45:00 to 2023-07-07 23:45:00\n",
      "Created 0\n",
      "Processing segment 113 in train set, length: 29, from 2023-07-08 23:00:00 to 2023-07-09 06:00:00\n",
      "Created 0\n",
      "Processing segment 114 in train set, length: 96, from 2023-07-10 23:00:00 to 2023-07-11 22:45:00\n",
      "Created 0\n",
      "Processing segment 115 in train set, length: 96, from 2023-07-12 23:00:00 to 2023-07-13 22:45:00\n",
      "Created 0\n",
      "Processing segment 116 in train set, length: 140, from 2023-07-14 23:00:00 to 2023-07-16 09:45:00\n",
      "Created 0\n",
      "Processing segment 117 in train set, length: 1381, from 2023-07-16 23:00:00 to 2023-07-31 08:00:00\n",
      "Created 5\n",
      "Processing segment 118 in train set, length: 17, from 2023-07-31 18:15:00 to 2023-07-31 22:15:00\n",
      "Created 0\n",
      "Processing segment 119 in train set, length: 2492, from 2023-09-01 00:00:00 to 2023-09-26 22:45:00\n",
      "Created 10\n",
      "Processing segment 120 in train set, length: 364, from 2023-09-27 20:00:00 to 2023-10-01 14:45:00\n",
      "Created 0\n",
      "Processing segment 121 in train set, length: 752, from 2023-10-01 23:00:00 to 2023-10-09 18:45:00\n",
      "Created 2\n",
      "Processing segment 122 in train set, length: 114, from 2023-10-10 18:30:00 to 2023-10-11 22:45:00\n",
      "Created 0\n",
      "Processing segment 123 in train set, length: 291, from 2023-10-12 11:30:00 to 2023-10-15 12:00:00\n",
      "Created 0\n",
      "Processing segment 124 in train set, length: 2020, from 2023-10-15 23:00:00 to 2023-11-05 23:45:00\n",
      "Created 8\n",
      "Processing segment 125 in train set, length: 801, from 2023-11-06 15:45:00 to 2023-11-14 23:45:00\n",
      "Created 2\n",
      "Processing segment 126 in train set, length: 977, from 2023-11-16 00:00:00 to 2023-11-26 04:00:00\n",
      "Created 3\n",
      "Processing segment 127 in train set, length: 96, from 2023-11-30 00:00:00 to 2023-11-30 23:45:00\n",
      "Created 0\n",
      "Processing segment 128 in train set, length: 337, from 2024-01-01 00:00:00 to 2024-01-04 12:00:00\n",
      "Created 0\n",
      "Processing segment 129 in train set, length: 1632, from 2024-01-15 00:00:00 to 2024-01-31 23:45:00\n",
      "Created 6\n",
      "Processing segment 130 in train set, length: 1012, from 2024-04-01 00:00:00 to 2024-04-11 12:45:00\n",
      "Created 3\n",
      "Processing segment 131 in train set, length: 390, from 2024-04-11 22:30:00 to 2024-04-15 23:45:00\n",
      "Created 0\n",
      "Processing segment 132 in train set, length: 4, from 2024-04-16 23:00:00 to 2024-04-16 23:45:00\n",
      "Created 0\n",
      "Processing segment 133 in train set, length: 4, from 2024-04-17 23:00:00 to 2024-04-17 23:45:00\n",
      "Created 0\n",
      "Processing segment 134 in train set, length: 4, from 2024-04-18 23:00:00 to 2024-04-18 23:45:00\n",
      "Created 0\n",
      "Processing segment 135 in train set, length: 100, from 2024-04-19 23:00:00 to 2024-04-20 23:45:00\n",
      "Created 0\n",
      "Processing segment 136 in train set, length: 4, from 2024-04-21 23:00:00 to 2024-04-21 23:45:00\n",
      "Created 0\n",
      "Processing segment 137 in train set, length: 40, from 2024-04-22 23:00:00 to 2024-04-23 08:45:00\n",
      "Created 0\n",
      "Processing segment 138 in train set, length: 33, from 2024-04-23 21:45:00 to 2024-04-24 05:45:00\n",
      "Created 0\n",
      "Processing segment 139 in train set, length: 4, from 2024-04-24 23:00:00 to 2024-04-24 23:45:00\n",
      "Created 0\n",
      "Processing segment 140 in train set, length: 86, from 2024-04-25 09:45:00 to 2024-04-26 07:00:00\n",
      "Created 0\n",
      "Processing segment 141 in train set, length: 100, from 2024-04-26 23:00:00 to 2024-04-27 23:45:00\n",
      "Created 0\n",
      "Processing segment 142 in train set, length: 100, from 2024-04-28 23:00:00 to 2024-04-29 23:45:00\n",
      "Created 0\n",
      "Processing segment 143 in train set, length: 4, from 2024-04-30 23:00:00 to 2024-04-30 23:45:00\n",
      "Created 0\n",
      "Processing segment 144 in train set, length: 333, from 2024-06-01 00:00:00 to 2024-06-04 11:00:00\n",
      "Created 0\n",
      "Processing segment 145 in train set, length: 4, from 2024-06-07 23:00:00 to 2024-06-07 23:45:00\n",
      "Created 0\n",
      "Processing segment 146 in train set, length: 4, from 2024-06-08 23:00:00 to 2024-06-08 23:45:00\n",
      "Created 0\n",
      "Processing segment 147 in train set, length: 1976, from 2024-06-10 09:00:00 to 2024-06-30 22:45:00\n",
      "Created 8\n",
      "Processing segment 148 in train set, length: 1152, from 2024-08-01 00:00:00 to 2024-08-12 23:45:00\n",
      "Created 4\n",
      "Processing segment 149 in train set, length: 4, from 2024-08-13 23:00:00 to 2024-08-13 23:45:00\n",
      "Created 0\n",
      "Processing segment 150 in train set, length: 4, from 2024-08-14 23:00:00 to 2024-08-14 23:45:00\n",
      "Created 0\n",
      "Processing segment 151 in train set, length: 4, from 2024-08-15 23:00:00 to 2024-08-15 23:45:00\n",
      "Created 0\n",
      "Processing segment 152 in train set, length: 4, from 2024-08-18 23:00:00 to 2024-08-18 23:45:00\n",
      "Created 0\n",
      "Processing segment 153 in train set, length: 4, from 2024-08-19 23:00:00 to 2024-08-19 23:45:00\n",
      "Created 0\n",
      "Processing segment 154 in train set, length: 4, from 2024-08-20 23:00:00 to 2024-08-20 23:45:00\n",
      "Created 0\n",
      "Processing segment 155 in train set, length: 4, from 2024-08-21 23:00:00 to 2024-08-21 23:45:00\n",
      "Created 0\n",
      "Processing segment 156 in train set, length: 4, from 2024-08-22 23:00:00 to 2024-08-22 23:45:00\n",
      "Created 0\n",
      "Processing segment 157 in train set, length: 4, from 2024-08-23 23:00:00 to 2024-08-23 23:45:00\n",
      "Created 0\n",
      "Processing segment 158 in train set, length: 4, from 2024-08-24 23:00:00 to 2024-08-24 23:45:00\n",
      "Created 0\n",
      "Processing segment 159 in train set, length: 4, from 2024-08-25 23:00:00 to 2024-08-25 23:45:00\n",
      "Created 0\n",
      "Processing segment 160 in train set, length: 4, from 2024-08-26 23:00:00 to 2024-08-26 23:45:00\n",
      "Created 0\n",
      "Processing segment 161 in train set, length: 4, from 2024-08-27 23:00:00 to 2024-08-27 23:45:00\n",
      "Created 0\n",
      "Processing segment 162 in train set, length: 4, from 2024-08-28 23:00:00 to 2024-08-28 23:45:00\n",
      "Created 0\n",
      "Processing segment 163 in train set, length: 4, from 2024-08-29 23:00:00 to 2024-08-29 23:45:00\n",
      "Created 0\n",
      "Processing segment 164 in train set, length: 4, from 2024-08-30 23:00:00 to 2024-08-30 23:45:00\n",
      "Created 0\n",
      "Processing segment 165 in train set, length: 4, from 2024-08-31 23:00:00 to 2024-08-31 23:45:00\n",
      "Created 0\n",
      "Samples created from train set: 154\n",
      "\n",
      "Gap summary for val set:\n",
      "Gap before 2020-02-29 20:30:00: 0 days 21:30:00 (from 2020-02-28 23:00:00 to 2020-02-29 20:30:00)\n",
      "Gap before 2021-02-01 00:00:00: 337 days 00:15:00 (from 2020-02-29 23:45:00 to 2021-02-01 00:00:00)\n",
      "Gap before 2021-05-01 00:00:00: 61 days 00:15:00 (from 2021-02-28 23:45:00 to 2021-05-01 00:00:00)\n",
      "Gap before 2024-02-01 00:00:00: 1001 days 06:00:00 (from 2021-05-05 18:00:00 to 2024-02-01 00:00:00)\n",
      "Gap before 2024-02-03 00:00:00: 0 days 19:00:00 (from 2024-02-02 05:00:00 to 2024-02-03 00:00:00)\n",
      "Gap before 2024-02-04 00:00:00: 0 days 12:00:00 (from 2024-02-03 12:00:00 to 2024-02-04 00:00:00)\n",
      "Gap before 2024-02-13 00:00:00: 1 days 00:15:00 (from 2024-02-11 23:45:00 to 2024-02-13 00:00:00)\n",
      "Gap before 2024-02-26 00:00:00: 0 days 12:00:00 (from 2024-02-25 12:00:00 to 2024-02-26 00:00:00)\n",
      "Gap before 2024-05-01 00:00:00: 61 days 00:15:00 (from 2024-02-29 23:45:00 to 2024-05-01 00:00:00)\n",
      "Gap before 2024-05-02 23:00:00: 0 days 11:00:00 (from 2024-05-02 12:00:00 to 2024-05-02 23:00:00)\n",
      "Gap before 2024-05-18 23:00:00: 1 days 00:15:00 (from 2024-05-17 22:45:00 to 2024-05-18 23:00:00)\n",
      "Gap before 2024-05-19 23:00:00: 0 days 08:30:00 (from 2024-05-19 14:30:00 to 2024-05-19 23:00:00)\n",
      "Segments in val set: 13\n",
      "Processing segment 0 in val set, length: 2685, from 2020-02-01 00:00:00 to 2020-02-28 23:00:00\n",
      "Created 11\n",
      "Processing segment 1 in val set, length: 14, from 2020-02-29 20:30:00 to 2020-02-29 23:45:00\n",
      "Created 0\n",
      "Processing segment 2 in val set, length: 2688, from 2021-02-01 00:00:00 to 2021-02-28 23:45:00\n",
      "Created 11\n",
      "Processing segment 3 in val set, length: 457, from 2021-05-01 00:00:00 to 2021-05-05 18:00:00\n",
      "Created 1\n",
      "Processing segment 4 in val set, length: 117, from 2024-02-01 00:00:00 to 2024-02-02 05:00:00\n",
      "Created 0\n",
      "Processing segment 5 in val set, length: 49, from 2024-02-03 00:00:00 to 2024-02-03 12:00:00\n",
      "Created 0\n",
      "Processing segment 6 in val set, length: 768, from 2024-02-04 00:00:00 to 2024-02-11 23:45:00\n",
      "Created 2\n",
      "Processing segment 7 in val set, length: 1201, from 2024-02-13 00:00:00 to 2024-02-25 12:00:00\n",
      "Created 4\n",
      "Processing segment 8 in val set, length: 384, from 2024-02-26 00:00:00 to 2024-02-29 23:45:00\n",
      "Created 0\n",
      "Processing segment 9 in val set, length: 145, from 2024-05-01 00:00:00 to 2024-05-02 12:00:00\n",
      "Created 0\n",
      "Processing segment 10 in val set, length: 1440, from 2024-05-02 23:00:00 to 2024-05-17 22:45:00\n",
      "Created 5\n",
      "Processing segment 11 in val set, length: 63, from 2024-05-18 23:00:00 to 2024-05-19 14:30:00\n",
      "Created 0\n",
      "Processing segment 12 in val set, length: 1156, from 2024-05-19 23:00:00 to 2024-05-31 23:45:00\n",
      "Created 4\n",
      "Samples created from val set: 38\n",
      "\n",
      "Gap summary for test set:\n",
      "Gap before 2023-08-01 23:00:00: 911 days 23:15:00 (from 2021-01-31 23:45:00 to 2023-08-01 23:00:00)\n",
      "Gap before 2023-12-01 00:00:00: 91 days 00:15:00 (from 2023-08-31 23:45:00 to 2023-12-01 00:00:00)\n",
      "Gap before 2023-12-06 00:00:00: 0 days 12:00:00 (from 2023-12-05 12:00:00 to 2023-12-06 00:00:00)\n",
      "Gap before 2023-12-07 12:45:00: 0 days 13:00:00 (from 2023-12-06 23:45:00 to 2023-12-07 12:45:00)\n",
      "Gap before 2023-12-09 00:00:00: 1 days 00:15:00 (from 2023-12-07 23:45:00 to 2023-12-09 00:00:00)\n",
      "Gap before 2023-12-10 23:30:00: 0 days 19:00:00 (from 2023-12-10 04:30:00 to 2023-12-10 23:30:00)\n",
      "Gap before 2023-12-14 00:00:00: 0 days 19:00:00 (from 2023-12-13 05:00:00 to 2023-12-14 00:00:00)\n",
      "Gap before 2023-12-17 00:00:00: 0 days 12:00:00 (from 2023-12-16 12:00:00 to 2023-12-17 00:00:00)\n",
      "Gap before 2023-12-24 17:30:00: 0 days 09:15:00 (from 2023-12-24 08:15:00 to 2023-12-24 17:30:00)\n",
      "Gap before 2024-03-01 00:00:00: 60 days 00:15:00 (from 2023-12-31 23:45:00 to 2024-03-01 00:00:00)\n",
      "Gap before 2024-03-04 00:00:00: 0 days 12:00:00 (from 2024-03-03 12:00:00 to 2024-03-04 00:00:00)\n",
      "Gap before 2024-03-07 00:00:00: 2 days 00:15:00 (from 2024-03-04 23:45:00 to 2024-03-07 00:00:00)\n",
      "Gap before 2024-03-21 23:00:00: 0 days 10:00:00 (from 2024-03-21 13:00:00 to 2024-03-21 23:00:00)\n",
      "Gap before 2024-07-01 23:00:00: 91 days 23:15:00 (from 2024-03-31 23:45:00 to 2024-07-01 23:00:00)\n",
      "Gap before 2024-07-09 23:00:00: 2 days 00:15:00 (from 2024-07-07 22:45:00 to 2024-07-09 23:00:00)\n",
      "Gap before 2024-07-10 23:00:00: 0 days 16:00:00 (from 2024-07-10 07:00:00 to 2024-07-10 23:00:00)\n",
      "Gap before 2024-07-11 23:00:00: 0 days 23:00:00 (from 2024-07-11 00:00:00 to 2024-07-11 23:00:00)\n",
      "Gap before 2024-07-28 23:00:00: 0 days 11:00:00 (from 2024-07-28 12:00:00 to 2024-07-28 23:00:00)\n",
      "Gap before 2024-09-01 23:00:00: 31 days 23:15:00 (from 2024-07-31 23:45:00 to 2024-09-01 23:00:00)\n",
      "Gap before 2024-09-02 23:00:00: 0 days 23:15:00 (from 2024-09-01 23:45:00 to 2024-09-02 23:00:00)\n",
      "Gap before 2024-09-03 23:00:00: 0 days 23:15:00 (from 2024-09-02 23:45:00 to 2024-09-03 23:00:00)\n",
      "Gap before 2024-09-04 23:00:00: 0 days 23:15:00 (from 2024-09-03 23:45:00 to 2024-09-04 23:00:00)\n",
      "Gap before 2024-09-05 23:00:00: 0 days 23:15:00 (from 2024-09-04 23:45:00 to 2024-09-05 23:00:00)\n",
      "Gap before 2024-09-06 23:00:00: 0 days 23:15:00 (from 2024-09-05 23:45:00 to 2024-09-06 23:00:00)\n",
      "Gap before 2024-09-07 23:00:00: 0 days 23:15:00 (from 2024-09-06 23:45:00 to 2024-09-07 23:00:00)\n",
      "Gap before 2024-09-08 23:00:00: 0 days 23:15:00 (from 2024-09-07 23:45:00 to 2024-09-08 23:00:00)\n",
      "Gap before 2024-09-09 23:00:00: 0 days 23:15:00 (from 2024-09-08 23:45:00 to 2024-09-09 23:00:00)\n",
      "Gap before 2024-09-10 23:00:00: 0 days 23:15:00 (from 2024-09-09 23:45:00 to 2024-09-10 23:00:00)\n",
      "Gap before 2024-09-25 14:15:00: 14 days 14:30:00 (from 2024-09-10 23:45:00 to 2024-09-25 14:15:00)\n",
      "Segments in test set: 30\n",
      "Processing segment 0 in test set, length: 2361, from 2021-01-07 09:45:00 to 2021-01-31 23:45:00\n",
      "Created 5\n",
      "Processing segment 1 in test set, length: 2884, from 2023-08-01 23:00:00 to 2023-08-31 23:45:00\n",
      "Created 6\n",
      "Processing segment 2 in test set, length: 433, from 2023-12-01 00:00:00 to 2023-12-05 12:00:00\n",
      "Created 1\n",
      "Processing segment 3 in test set, length: 96, from 2023-12-06 00:00:00 to 2023-12-06 23:45:00\n",
      "Created 0\n",
      "Processing segment 4 in test set, length: 45, from 2023-12-07 12:45:00 to 2023-12-07 23:45:00\n",
      "Created 0\n",
      "Processing segment 5 in test set, length: 115, from 2023-12-09 00:00:00 to 2023-12-10 04:30:00\n",
      "Created 0\n",
      "Processing segment 6 in test set, length: 215, from 2023-12-10 23:30:00 to 2023-12-13 05:00:00\n",
      "Created 0\n",
      "Processing segment 7 in test set, length: 241, from 2023-12-14 00:00:00 to 2023-12-16 12:00:00\n",
      "Created 0\n",
      "Processing segment 8 in test set, length: 706, from 2023-12-17 00:00:00 to 2023-12-24 08:15:00\n",
      "Created 1\n",
      "Processing segment 9 in test set, length: 698, from 2023-12-24 17:30:00 to 2023-12-31 23:45:00\n",
      "Created 1\n",
      "Processing segment 10 in test set, length: 241, from 2024-03-01 00:00:00 to 2024-03-03 12:00:00\n",
      "Created 0\n",
      "Processing segment 11 in test set, length: 96, from 2024-03-04 00:00:00 to 2024-03-04 23:45:00\n",
      "Created 0\n",
      "Processing segment 12 in test set, length: 1397, from 2024-03-07 00:00:00 to 2024-03-21 13:00:00\n",
      "Created 3\n",
      "Processing segment 13 in test set, length: 964, from 2024-03-21 23:00:00 to 2024-03-31 23:45:00\n",
      "Created 2\n",
      "Processing segment 14 in test set, length: 576, from 2024-07-01 23:00:00 to 2024-07-07 22:45:00\n",
      "Created 1\n",
      "Processing segment 15 in test set, length: 33, from 2024-07-09 23:00:00 to 2024-07-10 07:00:00\n",
      "Created 0\n",
      "Processing segment 16 in test set, length: 5, from 2024-07-10 23:00:00 to 2024-07-11 00:00:00\n",
      "Created 0\n",
      "Processing segment 17 in test set, length: 1589, from 2024-07-11 23:00:00 to 2024-07-28 12:00:00\n",
      "Created 3\n",
      "Processing segment 18 in test set, length: 292, from 2024-07-28 23:00:00 to 2024-07-31 23:45:00\n",
      "Created 0\n",
      "Processing segment 19 in test set, length: 4, from 2024-09-01 23:00:00 to 2024-09-01 23:45:00\n",
      "Created 0\n",
      "Processing segment 20 in test set, length: 4, from 2024-09-02 23:00:00 to 2024-09-02 23:45:00\n",
      "Created 0\n",
      "Processing segment 21 in test set, length: 4, from 2024-09-03 23:00:00 to 2024-09-03 23:45:00\n",
      "Created 0\n",
      "Processing segment 22 in test set, length: 4, from 2024-09-04 23:00:00 to 2024-09-04 23:45:00\n",
      "Created 0\n",
      "Processing segment 23 in test set, length: 4, from 2024-09-05 23:00:00 to 2024-09-05 23:45:00\n",
      "Created 0\n",
      "Processing segment 24 in test set, length: 4, from 2024-09-06 23:00:00 to 2024-09-06 23:45:00\n",
      "Created 0\n",
      "Processing segment 25 in test set, length: 4, from 2024-09-07 23:00:00 to 2024-09-07 23:45:00\n",
      "Created 0\n",
      "Processing segment 26 in test set, length: 4, from 2024-09-08 23:00:00 to 2024-09-08 23:45:00\n",
      "Created 0\n",
      "Processing segment 27 in test set, length: 4, from 2024-09-09 23:00:00 to 2024-09-09 23:45:00\n",
      "Created 0\n",
      "Processing segment 28 in test set, length: 4, from 2024-09-10 23:00:00 to 2024-09-10 23:45:00\n",
      "Created 0\n",
      "Processing segment 29 in test set, length: 419, from 2024-09-25 14:15:00 to 2024-09-29 22:45:00\n",
      "Created 0\n",
      "Samples created from test set: 23\n"
     ]
    }
   ],
   "source": [
    "def strat_random_sample(samples_df, strata_df):\n",
    "    # Merge the samples_df with the strata_df to get the strata labels for each sample\n",
    "    merged_df = samples_df.merge(strata_df, left_index=True, right_index=True)\n",
    "\n",
    "    # Perform stratified random sampling\n",
    "    sampled_df = merged_df.groupby('strata_label', group_keys=False).apply(lambda x: x.sample(hp.SAMPLE_SIZE, replace=True))\n",
    "\n",
    "    # Drop the strata_label column from the sampled dataframe\n",
    "    sampled_df = sampled_df.drop(columns='strata_label')\n",
    "\n",
    "    return sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "050d665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(flowdata_df):\n",
    "    window_size = hp.TOTAL_WINDOW\n",
    "\n",
    "    datasets = []\n",
    "    strata = []\n",
    "\n",
    "\n",
    "    train_df, val_df, test_df = month_based_train_val_test_split(flowdata_df, hp.TRAIN_VAL_TEST_SPLIT)\n",
    "    dfs = [train_df, val_df, test_df]\n",
    "    overlap = [True, True, False]\n",
    "\n",
    "    set_names = ['train', 'val', 'test']\n",
    "    results = {name: {} for name in set_names}\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "        # Actual code\n",
    "        strata_df = assign_strata(df)\n",
    "        samples_df, samples_strata_df = create_samples(df, strata_df, window_size, set_name, overlap=overlap[i])\n",
    "        #strat_sampled_df = strat_random_sample(samples_df, samples_strata_df)\n",
    "\n",
    "        datasets.append(samples_df)\n",
    "        strata.append(samples_strata_df)\n",
    "\n",
    "        # Stuff for printing output\n",
    "        #gap_mask = df.index.to_series().diff() > pd.Timedelta(minutes=15)\n",
    "        #segment_ids = gap_mask.cumsum()\n",
    "        #num_segments = segment_ids.nunique()\n",
    "        #results[set_names[i]]['num_segments'] = num_segments\n",
    "        #results[set_names[i]]['samples_df'] = samples_df\n",
    "        #results[set_names[i]]['strata_df'] = strata_df\n",
    "        #results[set_names[i]]['samples_strata_df'] = samples_strata_df\n",
    "        #results[set_names[i]]['strat_sampled_df'] = strat_sampled_df\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # --- Reporting ---\n",
    "    print('--- DATASET CHECKS ---')\n",
    "    # How many rows are in each month\n",
    "    df_month_strata = pd.DataFrame(index=flowdata_df.index)\n",
    "    df_month_strata['year_month'] = flowdata_df['timestamp'].dt.to_period('M')\n",
    "    print('Rows per month:')\n",
    "    print(df_month_strata['year_month'].value_counts().sort_index())\n",
    "\n",
    "    # How many rows are in each train/val/test set\n",
    "    for name, df in zip(set_names, dfs):\n",
    "        print(f'Rows in {name} set:', len(df))\n",
    "\n",
    "    for name in set_names:\n",
    "        # How many segments are in each train/val/test set\n",
    "        print(f'Segments in {name} set:', results[name]['num_segments'])\n",
    "\n",
    "        # How many samples are created from each train/val/test set\n",
    "        samples_df = results[name]['samples_df']\n",
    "        print(f'Samples created from {name} set:', len(samples_df))\n",
    "\n",
    "        # What are the start times of the samples (first 10)\n",
    "        if len(samples_df) > 0:\n",
    "            print(f'Sample start times in {name} set (first 10):', samples_df.index[:10])\n",
    "\n",
    "        # How many samples are in each strata\n",
    "        samples_strata_df = results[name]['samples_strata_df']\n",
    "        if 'strata' in samples_strata_df.columns:\n",
    "            print(f'Samples per strata in {name} set:')\n",
    "            print(strata_df['strata'].value_counts())\n",
    "\n",
    "        # How many samples are in each subset after stratified sampling\n",
    "        strat_sampled_df = results[name]['strat_sampled_df']\n",
    "        print(f'Samples after stratified sampling in {name} set:', len(strat_sampled_df))\n",
    "\n",
    "        # How many unique samples are in each subset after stratified sampling (to check for duplicates)\n",
    "        unique_samples = strat_sampled_df.drop_duplicates()\n",
    "        print(f'Unique samples after stratified sampling in {name} set:', len(unique_samples))\n",
    "\n",
    "        # How many samples are in each strata after stratified sampling (to check for balance)\n",
    "        if 'strata' in strat_sampled_df.columns:\n",
    "            print(f'Samples per strata after stratified sampling in {name} set:')\n",
    "            print(strat_sampled_df['strata'].value_counts())\n",
    "            \"\"\"\n",
    "\n",
    "    return datasets, strata\n",
    "\n",
    "datasets, strata = preprocess_data(flowdata_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
