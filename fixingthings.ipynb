{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2308e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from scipy.spatial.distance import euclidean\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from eda import plotGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d774a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "INPUT_WINDOW = 4\n",
    "FORECAST_WINDOW = 8\n",
    "TOTAL_WINDOW = INPUT_WINDOW + FORECAST_WINDOW\n",
    "MAX_GAP = 16\n",
    "\n",
    "#SENSOR_COLS = ['919', '157', '1959', '1016', '1994', '1870']\n",
    "SENSOR_COLS = [0,1,2,3,4,5]\n",
    "SENSOR_DMA_TO_ID = {\n",
    "    '919': 0, \n",
    "    '157': 1, \n",
    "    '1016': 2, \n",
    "    '1870': 3,\n",
    "    '1959': 4, \n",
    "    '1994': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13ff46de",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOWDATA_PATH = r\"C:\\Users\\ameli\\Documents\\Uni\\year-3-notes\\diss\\Dataset\\FlowData_for_SubsetGraph_12_with_7SensoredPipes.csv\"\n",
    "SUBSETGRAPH_PATH = r\"C:\\Users\\ameli\\Documents\\Uni\\year-3-notes\\diss\\Dataset\\SubsetGraph_12_with_7SensoredPipes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffc6776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_long_nan_sections(df, max_gap):\n",
    "    # create a mask for all of the rows with missing values\n",
    "    missing_vals = df.isna()\n",
    "    \n",
    "    prev_row_missing_vals = missing_vals.shift()\n",
    "\n",
    "    # find the rows where the value of a sensor changes from nan > value, or value > nan\n",
    "    transition_rows = missing_vals != prev_row_missing_vals\n",
    "\n",
    "    # assign an id number to each block of vals\n",
    "    block_ids = transition_rows.cumsum()\n",
    "\n",
    "    # find the length of each gap\n",
    "    gap_lengths = missing_vals.groupby(block_ids).transform('sum')\n",
    "\n",
    "    # identify all gaps which are longer than 4 hours\n",
    "    long_gaps = missing_vals & (gap_lengths > max_gap)\n",
    "\n",
    "    return long_gaps\n",
    "    \n",
    "def find_outlier_values(series):\n",
    "    rolling_med = series.rolling(window=24, center=True).median()\n",
    "    diff = (series - rolling_med).abs()\n",
    "    threshold = 5 * diff.rolling(window=24, center=True).median()\n",
    "    outlier_mask = diff > threshold\n",
    "    return outlier_mask\n",
    "\n",
    "def assign_strata(df_flowdata):\n",
    "\n",
    "    strata_dict = {\n",
    "        'time_of_day': {\n",
    "            'feature_origin': df_flowdata.index.hour,\n",
    "            'bins': [0, 6, 12, 14, 18, 22, 24],  \n",
    "            'labels': ['night', 'morning', 'midday', 'afternoon', 'evening', 'night']\n",
    "        },\n",
    "        'part_of_week': {\n",
    "            'feature_origin': df_flowdata.index.dayofweek,\n",
    "            'bins': [0, 5, 7], \n",
    "            'labels': ['weekday', 'weekend']\n",
    "        },\n",
    "        'season': {\n",
    "            'feature_origin': df_flowdata.index.month,\n",
    "            'bins': [0, 3, 6, 9, 12, 13], \n",
    "            'labels': ['winter', 'spring', 'summer', 'autumn', 'winter']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for strata_name, strata_info in strata_dict.items():\n",
    "        df_flowdata[strata_name] = pd.cut(\n",
    "            strata_info['feature_origin'],\n",
    "            bins=strata_info['bins'],\n",
    "            labels=strata_info['labels'],\n",
    "            right=False,  \n",
    "            include_lowest=True,\n",
    "            ordered=False\n",
    "        )\n",
    "\n",
    "    df_flowdata['strata'] = df_flowdata['time_of_day'].astype(str) + '_' + df_flowdata['part_of_week'].astype(str) + '_' + df_flowdata['season'].astype(str)\n",
    "\n",
    "    return df_flowdata\n",
    "\n",
    "\n",
    "def create_samples(df_flowdata):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        df: df_flowdata - contains columns with flow data, as well as a column defining strata\n",
    "\n",
    "    Outpus:\n",
    "        df: windows_df - col\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    gap_mask = df_flowdata.index.to_series().diff() > pd.Timedelta(minutes=15)\n",
    "    df_flowdata['segment_id'] = gap_mask.cumsum()\n",
    "\n",
    "    windows_df = pd.DataFrame(columns=SENSOR_COLS)\n",
    "    strata_series = pd.Series(dtype='object', name='strata')\n",
    "\n",
    "    for _, segment in df_flowdata.groupby('segment_id'):\n",
    "        segment = segment.drop(columns='segment_id')\n",
    "\n",
    "        sensor_values = segment[SENSOR_COLS].values\n",
    "        strata_values = segment['strata'].values\n",
    "\n",
    "        i = 0\n",
    "        while i + TOTAL_WINDOW <= len(segment):\n",
    "            row = {\n",
    "                col: sensor_values[i:i + TOTAL_WINDOW, idx]\n",
    "                for idx, col in enumerate(SENSOR_COLS)\n",
    "            }\n",
    "\n",
    "            windows_df.loc[len(windows_df)] = row\n",
    "            strata_series.loc[len(windows_df)] = strata_values[i]\n",
    "\n",
    "            i += TOTAL_WINDOW\n",
    "\n",
    "    return windows_df, strata_series\n",
    "    \n",
    "def strat_random_sampling(windows_df, strata_series):\n",
    "    counts = strata_series.value_counts()\n",
    "    min_count = counts.min()\n",
    "\n",
    "    sampled_idx = strata_series.groupby(strata_series).sample(n=min_count, random_state=42).index\n",
    "\n",
    "    windows_df_sampled = windows_df.loc[sampled_idx]\n",
    "    strata_series_sampled = strata_series.loc[sampled_idx]\n",
    "\n",
    "    return windows_df_sampled, strata_series_sampled\n",
    "\n",
    "\n",
    "def train_val_test_split(windows_df_sampled, strata_series_sampled):\n",
    "\n",
    "    train_idx, temp_idx = train_test_split(\n",
    "        windows_df_sampled.index,\n",
    "        test_size=0.3,\n",
    "        stratify=strata_series_sampled.loc[windows_df_sampled.index],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    train_df = windows_df_sampled.loc[train_idx]\n",
    "    train_strata = strata_series_sampled.loc[train_idx]\n",
    "\n",
    "    val_idx, test_idx = train_test_split(\n",
    "        temp_idx,\n",
    "        test_size=0.5,\n",
    "        stratify=strata_series_sampled.loc[temp_idx],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    val_df = windows_df_sampled.loc[val_idx]\n",
    "    val_strata = strata_series_sampled.loc[val_idx]\n",
    "\n",
    "    test_df = windows_df_sampled.loc[test_idx]\n",
    "    test_strata = strata_series_sampled.loc[test_idx]\n",
    "\n",
    "    \n",
    "    return [train_df, val_df, test_df], [train_strata, val_strata, test_strata]\n",
    "\n",
    "\n",
    "def preprocess_flowdata(path):\n",
    "\n",
    "    # Reading in the flow data file\n",
    "    df_flowdata = pd.read_csv(path, index_col=0)\n",
    "    df_flowdata.index = pd.to_datetime(df_flowdata.index, format='%d/%m/%Y %H:%M')\n",
    "\n",
    "    # Removing a sensor with a large number of missing values\n",
    "    df_flowdata = df_flowdata.drop('1615', axis=1)\n",
    "\n",
    "    df_flowdata = df_flowdata.rename(columns=SENSOR_DMA_TO_ID)\n",
    "    df_flowdata = df_flowdata.sort_index(axis=1)\n",
    "\n",
    "    # Removing rows which have outliers or are part of long sections of missing values\n",
    "    rows_to_remove = pd.Series(False, index=df_flowdata.index) \n",
    "    for col in df_flowdata.columns:\n",
    "        rows_to_remove |= find_long_nan_sections(df_flowdata[col], MAX_GAP)\n",
    "        rows_to_remove |= find_outlier_values(df_flowdata[col])\n",
    "    df_flowdata = df_flowdata[rows_to_remove == False]\n",
    "\n",
    "    # Imputing short ranges of missing values\n",
    "    df_flowdata = df_flowdata.interpolate(method='spline', order = 3)\n",
    "\n",
    "    # Applying a transformation\n",
    "    df_flowdata = df_flowdata.apply(np.log1p)\n",
    "\n",
    "    # Stratified random sampling\n",
    "    df_flowdata = assign_strata(df_flowdata)\n",
    "    windows_df, strata_series = create_samples(df_flowdata)\n",
    "    windows_df_sampled, strata_series_sampled = strat_random_sampling(windows_df, strata_series)\n",
    "\n",
    "    # Splitting into train val and test sets\n",
    "    split_df, split_df_strata = train_val_test_split(windows_df_sampled, strata_series_sampled)\n",
    "   \n",
    "    return split_df, split_df_strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7154d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_node_features, df_node_features_strata = preprocess_flowdata(FLOWDATA_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
